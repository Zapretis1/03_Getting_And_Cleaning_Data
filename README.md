To your attention-----------------You've been chosen to review this assignement. Thank you in advance for your time! I believe such peer reviewed work is both beneficial to students who submit and get thoughtful advice from their peers as well as for reviewers who can discover alternative ways of solving the same problem!As it has been emphasized on [David Hood's][david hood] webpage and in the discussion forum, reviewing should be kept simple.This is why the submission encompasses:1.	The submitted tidy dataset [`averaged_data.txt`](#averageddata); the repository contains both the text and zipped version of the file for easy [download](#download)2.	The required scripts [`run_analysis.R`](#runanalysis) which processes the data and [`setup_review.R`](#setupreview) which helps the reviewer3.	A code book [`CodeBook.md`](#codebook) which explains what the data set contains4.	The present `README.md` which explains the files mentioned hereaboveEasy reviewing--------------To make reviewing easy:1.	Copy to your computer the R scripts2.	Run [`setup_review.R`](#setupreview)3.	Run [`run_analysis.R`](#runanalysis)4.	Have a look at the [`CodeBook.md`](#codebook)5.	Have a look at the data in [`averaged_data.txt`](#averageddata)Data `averaged_data.txt` <a id="averageddata" />-----------------------This file contains the newly created dataset with averaged features with respect to both subject's who have taken part in the study and to one of the six activities they performed. The precision of the data has been limited to 5 digits. Surprisingly enough, higher precision would not allow both the created data within the script and the downloaded data created with `write.table` and loaded with `read.table` to match.The produced data can be viewed directly on the GitHub repository by clicking on the file [`averaged_data.txt`][datalink].The produced data can be loaded into R using the command `data_read<- read.table("averaged_data.txt", fileEncoding = "UTF-8")` from the appropriate location.The produced data will be reloaded into R as a checking procedure at the end of the [`run_analysis.R`](#runanalysis) script.[datalink]: https://github.com/Zapretis1/03_Getting_And_Cleaning_Data/blob/master/averaged_data.txtScript `run_analysis.R` <a id="runanalysis" />-----------------------This R script called run_analysis.R does the following:1.	Loads the data into R2.	Merges the training and the test sets to create one data set.3.	Extracts only the measurements on the mean and standard deviation for each measurement.4.	Uses descriptive activity names to name the activities in the data set5.	Appropriately labels the data set with descriptive variable names.6.	From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.7.	Writes the independent tidy data set in a text file8.	Checks that the created data and the exported and reimported data matchThe R script can be viewed in the browser by clicking on the file [`run_analysis.R`][runanalysislink].[runanalysislink]: https://github.com/Zapretis1/03_Getting_And_Cleaning_Data/blob/master/run_analysis.RScript `setup_review.R` <a id="setupreview" />-----------------------This script helps the reviewer put himself in the shoes of the submitting student.It helps fellow markers setting up the environment to make peer reviewing easier, faster and straightforward.This scripts downloads the raw data in an appropriate directory and unzips the files.The user ends up with a ready-to-use environment for running the script created for the assignment [`run_analysis.R`][runanalysislink].The R script can be viewed in the browser by clicking on the file [`setup_review.R`][setupreviewlink][setupreviewlink]: https://github.com/Zapretis1/03_Getting_And_Cleaning_Data/blob/master/setup_review.RCode Book <a id="codebook" />---------The Code Book modifies and updates the available codebooks with the data to indicate all the variables and summaries calculated, along with units, and any other relevant information.Check list----------* in the submission box: "tidy data as per the ReadMe that can be read into R with read.table(header=TRUE) {listing any settings you have changed from the default}” This is just to make it really easy for your reviewer."* data has headings* variables in different columns* one entry per line* no duplicate columns* this is the long form as mentioned in the rubric as either long or wide form is acceptableThe output should be the tidy data set you submitted for part 1.You should include a README.md in the repo describing how the script worksand the code book describing the variablesExplain how to read in data within R to check it's tidinessProvide the R code that can be sourced (data download and load in R)Prerequisites-------------To make your grading as easy as possible the following files are provided along with the assignment's deliverables.*	A script `review_setup.R` to set up the review environment; you can run this script from any location on your computerRequires the installation of packech downloaderYou have two alternatives: either [run a script](#runscript) or create the reviewing environment through [manual set-up](#manualsetup)Click averaged_data.zipThen view rawSave the file in the directory of the project to be reviewed"https://github.com/Zapretis1/03_Getting_And_Cleaning_Data/blob/master/averaged_data.zip"download("https://github.com/Zapretis1/03_Getting_And_Cleaning_Data/blob/master/appleorange.csv", destfile="appleorange_SPI.csv")Running the script <a id="runscript" />------------------This script assumes R is installed on the computer (or course it is if you are reviewing this work).You can run the script `review_setup.R` from any location on your computer.The `review_setup.R` script will create a directory `03_week4_peer_graded_assignment` and download and unzip the data file into it.Manual setup  <a id="manualsetup" />------------1.	Download the file containing the data [getdata_projectfiles_UCI HAR Dataset.zip][uci data]; you can download it for example into a directory named `03_week4_peer_graded_assignment`2.	Use the default command to unzip it in the `03_week4_peer_graded_assignment` directory3.	As a result you get the directory UCI HAR Dataset with the following content and architecture (2 directories and 4 text files):	*	`test` directory with test data	*	`train` directory with train data	*	`activity_labels.txt`	*	`features.txt`	*	`features_info.txt`	*	`README.txt`## 1) Appropriately labels the data set with descriptive variable names.Assign names to the columns of test and training data with the features' list with the subject_idThe names are descriptive in the sense that they are acronyms indicating what each feature represents in a compact formSee the `features_info.txt` for detailed explanation of what each feature represents and how it is computedOnly -mean() and -meanFreq() measurements are extracted.Ultimate features corresponding to angle values where variables suffixed with "Mean" appear, are excluded from the extraction.They represent values computed based on means of gravity, gyro values.All columns labelled with -std() are extractedExplain what the script does and then generates a tidy data text file that meets the principles of …etcHeaders are variable names, one variable is stored in one column, there is one entry per row, there is no multiple observational units since we summarized the data for each person and each activityDiscussion about tidy data as in [David Hood's][david hood] thread and [Hadley Wickam's][hadley wickham] articleAlthough the values of the features have been averaged in step 5, the __names of the features have deliberately been untouched__ so that the analyst can refer to the original data using the same name.Existence of the Code Book and it's roleEncountered difficulties and Possible improvement-------------------------------------------------Automatic download <a id="manualsetup" /> of all filesCredits-------The [Dingus][] web page for converting markdown source into html source and preview the layout.[dingus]: https://daringfireball.net/projects/markdown/dingus "Optional Title Here"[david hood]: https://thoughtfulbloke.wordpress.com/2015/09/09/getting-and-cleaning-the-assignment/[hadley wickham]: http://vita.had.co.nz/papers/tidy-data.pdf[uci data]: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip "Optional Title Here"__EOF__